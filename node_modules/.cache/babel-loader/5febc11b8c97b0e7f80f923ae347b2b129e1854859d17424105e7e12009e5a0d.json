{"ast":null,"code":"function tokenize(text, tokens) {\n  const compiledRegex = new RegExp(Object.entries(tokens).map(_ref => {\n    let [type, regex] = _ref;\n    return `(?<${type}>${regex.source})`;\n  }).join('|'), 'yi');\n  let index = 0;\n  const ast = [];\n  while (index < text.length) {\n    compiledRegex.lastIndex = index;\n    const result = text.match(compiledRegex);\n    if (result !== null) {\n      const [type, text] = Object.entries(result.groups).find(_ref2 => {\n        let [name, group] = _ref2;\n        return group !== undefined;\n      });\n      index += text.length;\n      if (!type.startsWith('_')) {\n        ast.push({\n          type,\n          text\n        });\n      }\n    } else {\n      throw new Error(`No matching tokenizer rule found at: [${text.substring(index)}]`);\n    }\n  }\n  return ast;\n}\nmodule.exports = {\n  tokenize\n};","map":{"version":3,"names":["tokenize","text","tokens","compiledRegex","RegExp","Object","entries","map","_ref","type","regex","source","join","index","ast","length","lastIndex","result","match","groups","find","_ref2","name","group","undefined","startsWith","push","Error","substring","module","exports"],"sources":["/Users/user/dig_develop/solo_project/node_modules/knex/lib/dialects/sqlite3/schema/internal/tokenizer.js"],"sourcesContent":["function tokenize(text, tokens) {\n  const compiledRegex = new RegExp(\n    Object.entries(tokens)\n      .map(([type, regex]) => `(?<${type}>${regex.source})`)\n      .join('|'),\n    'yi'\n  );\n\n  let index = 0;\n  const ast = [];\n\n  while (index < text.length) {\n    compiledRegex.lastIndex = index;\n    const result = text.match(compiledRegex);\n\n    if (result !== null) {\n      const [type, text] = Object.entries(result.groups).find(\n        ([name, group]) => group !== undefined\n      );\n\n      index += text.length;\n\n      if (!type.startsWith('_')) {\n        ast.push({ type, text });\n      }\n    } else {\n      throw new Error(\n        `No matching tokenizer rule found at: [${text.substring(index)}]`\n      );\n    }\n  }\n\n  return ast;\n}\n\nmodule.exports = {\n  tokenize,\n};\n"],"mappings":"AAAA,SAASA,QAAQA,CAACC,IAAI,EAAEC,MAAM,EAAE;EAC9B,MAAMC,aAAa,GAAG,IAAIC,MAAM,CAC9BC,MAAM,CAACC,OAAO,CAACJ,MAAM,CAAC,CACnBK,GAAG,CAACC,IAAA;IAAA,IAAC,CAACC,IAAI,EAAEC,KAAK,CAAC,GAAAF,IAAA;IAAA,OAAM,MAAKC,IAAK,IAAGC,KAAK,CAACC,MAAO,GAAE;EAAA,EAAC,CACrDC,IAAI,CAAC,GAAG,CAAC,EACZ,IACF,CAAC;EAED,IAAIC,KAAK,GAAG,CAAC;EACb,MAAMC,GAAG,GAAG,EAAE;EAEd,OAAOD,KAAK,GAAGZ,IAAI,CAACc,MAAM,EAAE;IAC1BZ,aAAa,CAACa,SAAS,GAAGH,KAAK;IAC/B,MAAMI,MAAM,GAAGhB,IAAI,CAACiB,KAAK,CAACf,aAAa,CAAC;IAExC,IAAIc,MAAM,KAAK,IAAI,EAAE;MACnB,MAAM,CAACR,IAAI,EAAER,IAAI,CAAC,GAAGI,MAAM,CAACC,OAAO,CAACW,MAAM,CAACE,MAAM,CAAC,CAACC,IAAI,CACrDC,KAAA;QAAA,IAAC,CAACC,IAAI,EAAEC,KAAK,CAAC,GAAAF,KAAA;QAAA,OAAKE,KAAK,KAAKC,SAAS;MAAA,CACxC,CAAC;MAEDX,KAAK,IAAIZ,IAAI,CAACc,MAAM;MAEpB,IAAI,CAACN,IAAI,CAACgB,UAAU,CAAC,GAAG,CAAC,EAAE;QACzBX,GAAG,CAACY,IAAI,CAAC;UAAEjB,IAAI;UAAER;QAAK,CAAC,CAAC;MAC1B;IACF,CAAC,MAAM;MACL,MAAM,IAAI0B,KAAK,CACZ,yCAAwC1B,IAAI,CAAC2B,SAAS,CAACf,KAAK,CAAE,GACjE,CAAC;IACH;EACF;EAEA,OAAOC,GAAG;AACZ;AAEAe,MAAM,CAACC,OAAO,GAAG;EACf9B;AACF,CAAC"},"metadata":{},"sourceType":"script","externalDependencies":[]}